{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "from fastai.callbacks.hooks import *\n",
    "from fastai.utils.mem import *\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "from numpy import array\n",
    "\n",
    "import skimage\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to one-hot\n",
    "# 32 x image\n",
    "# for each pixel, have 1 value that is 1 (corresponding to that pixel's channel/class), and 31 values that are 0\n",
    "frame_1hot = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"/home/jupyter/.fastai/data/camvid/opticalFlow/train.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, frame1 = cap.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY) \n",
    "hsv = np.zeros_like(frame1)\n",
    "hsv[...,1] = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prvs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeIT(ang, mag, hsv, VISUALIZE_FLOW):\n",
    "        if VISUALIZE_FLOW:\n",
    "            hsv[...,0] = ang*180/np.pi/2\n",
    "            hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "            rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "\n",
    "            cv2.imshow('frame2',rgb)\n",
    "            k = cv2.waitKey(30) & 0xff\n",
    "        if k == 27:\n",
    "            pass\n",
    "        elif k == ord('s'):\n",
    "            cv2.imwrite('opticalfb.png',frame2)\n",
    "            cv2.imwrite('opticalhsv.png',rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on <10 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, frame2 = cap.read()\n",
    "next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "magAng = np.stack([mag, ang])\n",
    "type(magAng)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save to an image\n",
    "Check to see if image works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgTest = cv2.imwrite('optFlow67.png', magAng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try on ALL frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-7809c416a989>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalcOpticalFlowFarneback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprvs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;31m# Save mag, ang as information relevant to motion at each pixel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# True == visualize the motion\n",
    "VISUALIZE_FLOW = False\n",
    "count = 1\n",
    "\n",
    "while(1):\n",
    "    # compute optical flow for each frame\n",
    "    ret, frame2 = cap.read()\n",
    "    next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "    # Save mag, ang as information relevant to motion at each pixel \n",
    "    mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "\n",
    "    # Combine mag, ang into one variable \n",
    "    magang = np.stack([mag, ang]) # frame2.shape x 2\n",
    "    \n",
    "    \n",
    "    cv2.imwrite(f'/home/jupyter/.fastai/data/camvid/opticalFlow/optFlow{count}.png', magang)\n",
    "    \n",
    "#     save_image(magang, f'optFlow{count}.png')\n",
    "    # save out frame2 motion\n",
    "#     save_image(mag, ...) # how much motion?\n",
    "#     save_image(ang, ...) # motion in what direction?\n",
    "\n",
    "\n",
    "    # Set prvs to next image\n",
    "    prvs = next\n",
    "    count += 1\n",
    "    \n",
    "    # visualize the motion of frame2\n",
    "    visualizeIT(ang, mag, hsv, VISUALIZE_FLOW)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling and One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in frames:\n",
    "    # load frame_1hot for frame\n",
    "    ...\n",
    "    # load magang for frame\n",
    "    ...\n",
    "  \n",
    "    # combine flow and segmentation information\n",
    "    features = np.dot(frame_1hot, magang) # 32x2ximage\n",
    "    \n",
    "    # pool to downsample\n",
    "    # use mean pooling over 3x3 grid on the image dimensions\n",
    "    # 32x2x(3x3) vector of length 576\n",
    "    features = pool(features)\n",
    "    \n",
    "    vector = np.ravel(features)\n",
    "    \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
