{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision import *\n",
    "from fastai.callbacks.hooks import *\n",
    "from fastai.utils.mem import *\n",
    "\n",
    "\n",
    "from PIL import Image\n",
    "from numpy import array\n",
    "\n",
    "import skimage\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def segs2onehot(frame, nchannels):\n",
    "    \"\"\"\n",
    "    Converts a tensor of shape (1, imgx, imgy)\n",
    "    with discrete values in the range(nchannels)\n",
    "    to a onehot style tensor of shape (nchannels, imgx, imgy)\n",
    "    \"\"\"\n",
    "    *_, nx, ny = frame.shape\n",
    "    x,y = np.meshgrid(np.arange(nx), np.arange(ny))\n",
    "    res = np.zeros((nchannels, nx, ny))\n",
    "    res[frame.T.ravel(), x.ravel(), y.ravel()] = 1\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to one-hot\n",
    "# 32 x image\n",
    "# for each pixel, have 1 value that is 1 (corresponding to that pixel's channel/class), and 31 values that are 0\n",
    "frame_1hot = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"/home/jupyter/.fastai/data/camvid/opticalFlow/train.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, frame1 = cap.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "prvs = cv2.cvtColor(frame1,cv2.COLOR_BGR2GRAY) \n",
    "hsv = np.zeros_like(frame1)\n",
    "hsv[...,1] = 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(prvs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use this method to visualize images\n",
    "\n",
    "- Test out save to image portion of the method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeIT(ang, mag, hsv, VISUALIZE_FLOW):\n",
    "        if VISUALIZE_FLOW:\n",
    "            hsv[...,0] = ang*180/np.pi/2\n",
    "            hsv[...,2] = cv2.normalize(mag,None,0,255,cv2.NORM_MINMAX)\n",
    "            rgb = cv2.cvtColor(hsv,cv2.COLOR_HSV2BGR)\n",
    "\n",
    "            cv2.imshow('frame2',rgb)\n",
    "            k = cv2.waitKey(30) & 0xff\n",
    "        if k == 27:\n",
    "            pass\n",
    "        elif k == ord('s'):\n",
    "            \n",
    "            # Not sure if this saving method will work\n",
    "            cv2.imwrite('opticalfb.png',frame2)\n",
    "            cv2.imwrite('opticalhsv.png',rgb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test on <10 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ret, frame2 = cap.read()\n",
    "next = cv2.cvtColor(frame2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "flow = cv2.calcOpticalFlowFarneback(prvs, next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "\n",
    "mag, ang = (flow[..., 0], flow[..., 1])\n",
    "# mag, ang = cv2.cartToPolar(flow[..., 0], flow[..., 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "magAng = np.stack([mag, ang])\n",
    "type(magAng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert from torch tensor to numpy array \n",
    "magAngImage = torch.from_numpy(magAng)\n",
    "angImage = torch.from_numpy(ang)\n",
    "magImage = torch.from_numpy(mag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save to an image\n",
    "Convert numpy array to torch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# does saving the cartesian coordinates as images preserve the cartesian coords? \n",
    "# Do I need to do anything else with the image / matrix before the next step?\n",
    "\n",
    "save_image(magAngImage, 'MagAngImage33.png')\n",
    "save_image(magImage, 'magImage33.png')\n",
    "save_image(angImage, 'angImage33.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use this for mag or ang, but not for magAng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "\n",
    "matplotlib.image.imsave('MagOnly.png', mag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try on ALL frames\n",
    "- this loop works "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-da4b91c9a7f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# compute optical flow for each frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframe2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mnext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mflow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalcOpticalFlowFarneback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprvs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.1.0) /io/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "# True == visualize the motion\n",
    "VISUALIZE_FLOW = False\n",
    "count = 1\n",
    "\n",
    "while(1):\n",
    "    # compute optical flow for each frame\n",
    "    ret, frame2 = cap.read()\n",
    "    next = cv2.cvtColor(frame2,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    flow = cv2.calcOpticalFlowFarneback(prvs,next, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "\n",
    "    # Save mag, ang as information relevant to motion at each pixel \n",
    "#     mag, ang = cv2.cartToPolar(flow[...,0], flow[...,1])\n",
    "    mag, ang = (flow[..., 0], flow[..., 1])\n",
    "\n",
    "    # Combine mag, ang into one variable \n",
    "    magAng = np.stack([mag, ang]) # frame2.shape x 2\n",
    "    magAngImage = torch.from_numpy(magAng)\n",
    "    \n",
    "    save_image(magAngImage, f'/home/jupyter/.fastai/data/camvid/opticalFlow/optFlow{count}.png')\n",
    "#     cv2.imwrite(f'/home/jupyter/.fastai/data/camvid/opticalFlow/optFlow{count}.png', magAngImage)\n",
    "    \n",
    "#     save_image(magang, f'optFlow{count}.png')\n",
    "    # save out frame2 motion\n",
    "#     save_image(mag, ...) # how much motion?\n",
    "#     save_image(ang, ...) # motion in what direction?\n",
    "\n",
    "\n",
    "    # Set prvs to next image\n",
    "    prvs = next\n",
    "    count += 1\n",
    "    \n",
    "    # visualize the motion of frame2\n",
    "#     visualizeIT(ang, mag, hsv, VISUALIZE_FLOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20398"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling and One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame in frames:\n",
    "    # load frame_1hot for frame\n",
    "    ...\n",
    "    # load magang for frame\n",
    "    ...\n",
    "  \n",
    "    # combine flow and segmentation information\n",
    "    features = np.dot(frame_1hot, magang) # 32x2ximage\n",
    "    \n",
    "    # pool to downsample\n",
    "    # use mean pooling over 3x3 grid on the image dimensions\n",
    "    # 32x2x(3x3) vector of length 576\n",
    "    features = pool(features)\n",
    "    \n",
    "    vector = np.ravel(features)\n",
    "    \n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean pooling\n",
    "from torch.nn.modules.pooling import AvgPool2d\n",
    "# pool = AvgPool2d((img.shape[0]//3,img.shape[1]//3))\n",
    "# ...\n",
    "# for frame in frames:\n",
    "# ...\n",
    "# features = pool(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
